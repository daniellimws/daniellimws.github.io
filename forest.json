{"dlws-0002":{"title":"Public bibliographies","taxon":null,"tags":[],"route":"dlws-0002.xml","metas":{}},"dlws-0006":{"title":"Sampling-based race detection","taxon":"Bibliography","tags":[],"route":"dlws-0006.xml","metas":{}},"dlws-0005":{"title":"Trace theory","taxon":"Bibliography","tags":[],"route":"dlws-0005.xml","metas":{}},"ang-mathur-prefix-2024":{"title":"Predictive Monitoring with Strong Trace Prefixes","taxon":"Reference","tags":["racepred","trace","paper"],"route":"ang-mathur-prefix-2024.xml","metas":{"bibtex":"@InProceedings{10.1007/978-3-031-65630-9_9,\nauthor=\"Ang, Zhendong\nand Mathur, Umang\",\neditor=\"Gurfinkel, Arie\nand Ganesh, Vijay\",\ntitle=\"Predictive Monitoring with Strong Trace Prefixes\",\nbooktitle=\"Computer Aided Verification\",\nyear=\"2024\",\npublisher=\"Springer Nature Switzerland\",\naddress=\"Cham\",\npages=\"182--204\",\nabstract=\"Runtime predictive analyses enhance coverage of traditional dynamic analyses based bug detection techniques by identifying a space of feasible reorderings of the observed execution and determining if any reordering in this space witnesses the violation of some desired safety property. The most popular approach for modelling the space of feasible reorderings is through Mazurkiewicz's trace equivalence. The simplicity of the framework also gives rise to efficient predictive analyses, and has been the de facto means for obtaining space and time efficient algorithms for monitoring concurrent programs.\",\nisbn=\"978-3-031-65630-9\"\n}","doi":"10.1007/978-3-031-65630-9_9"}},"farzan-grain-2024-iarcs":{"title":"Coarser Equivalences for Causal Concurrency","taxon":"Reference","tags":["talk","racepred","trace"],"route":"farzan-grain-2024-iarcs.xml","metas":{"external":"Https://www.youtube.com/watch?v=hYJv7Pf53yU","venue":"IARCS Verification Seminar"}},"zheng-mathur-pavlogiannis-osr-2024":{"title":"Optimistic Prediction of Synchronization-Reversal Data Races","taxon":"Reference","tags":["racepred","trace","paper"],"route":"zheng-mathur-pavlogiannis-osr-2024.xml","metas":{"bibtex":"@Inproceedings{10.1145/3597503.3639099,\nauthor = {Shi, Zheng and Mathur, Umang and Pavlogiannis, Andreas},\ntitle = {Optimistic Prediction of Synchronization-Reversal Data Races},\nyear = {2024},\nisbn = {9798400702174},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3597503.3639099},\ndoi = {10.1145/3597503.3639099},\nabstract = {Dynamic data race detection has emerged as a key technique for ensuring reliability of concurrent software in practice. However, dynamic approaches can often miss data races owing to non-determinism in the thread scheduler. Predictive race detection techniques cater to this shortcoming by inferring alternate executions that may expose data races without re-executing the underlying program. More formally, the dynamic data race prediction problem asks, given a trace σ of an execution of a concurrent program, can σ be correctly reordered to expose a data race? Existing state-of-the art techniques for data race prediction either do not scale to executions arising from real world concurrent software, or only expose a limited class of data races, such as those that can be exposed without reversing the order of synchronization operations.In general, exposing data races by reasoning about synchronization reversals is an intractable problem. In this work, we identify a class of data races, called Optimistic Sync(hronization)-Reversal races that can be detected in a tractable manner and often include non-trivial data races that cannot be exposed by prior tractable techniques. We also propose a sound algorithm OSR for detecting all optimistic sync-reversal data races in overall quadratic time, and show that the algorithm is optimal by establishing a matching lower bound. Our experiments demonstrate the effectiveness of OSR--- on our extensive suite of benchmarks, OSR reports the largest number of data races, and scales well to large execution traces.},\nbooktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},\narticleno = {134},\nnumpages = {13},\nlocation = {Lisbon, Portugal},\nseries = {ICSE '24}\n}","doi":"10.1145/3597503.3639099"}},"farzan-mathur-grain-2024":{"title":"Coarser Equivalences for Causal Concurrency","taxon":"Reference","tags":["trace","paper"],"route":"farzan-mathur-grain-2024.xml","metas":{"bibtex":"@Article{10.1145/3632873,\nauthor = {Farzan, Azadeh and Mathur, Umang},\ntitle = {Coarser Equivalences for Causal Concurrency},\nyear = {2024},\nissue_date = {January 2024},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {8},\nnumber = {POPL},\nurl = {https://doi.org/10.1145/3632873},\ndoi = {10.1145/3632873},\nabstract = {Trace theory (formulated by Mazurkiewicz in 1987) is a principled framework for defining equivalence relations for concurrent program runs based on a commutativity relation over the set of atomic steps taken by individual program threads. Its simplicity, elegance, and algorithmic efficiency makes it useful in many different contexts including program verification and testing. It is well-understood that the larger the equivalence classes are, the more benefits they would bring to the algorithms and applications that use them. In this paper, we study relaxations of trace equivalence with the goal of maintaining its algorithmic advantages. We first prove that the largest appropriate relaxation of trace equivalence, an equivalence relation that preserves the order of steps taken by each thread and what write operation each read operation observes, does not yield efficient algorithms. Specifically, we prove a linear space lower bound for the problem of checking, in a streaming setting, if two arbitrary steps of a concurrent program run are causally concurrent (i.e. they can be reordered in an equivalent run) or causally ordered (i.e. they always appear in the same order in all equivalent runs). The same problem can be decided in constant space for trace equivalence. Next, we propose a new commutativity-based notion of equivalence called grain equivalence that is strictly more relaxed than trace equivalence, and yet yields a constant space algorithm for the same problem. This notion of equivalence uses commutativity of grains, which are sequences of atomic steps, in addition to the standard commutativity from trace theory. We study the two distinct cases when the grains are contiguous subwords of the input program run and when they are not, formulate the precise definition of causal concurrency in each case, and show that they can be decided in constant space, despite being strict relaxations of the notion of causal concurrency based on trace equivalence.},\njournal = {Proc. ACM Program. Lang.},\nmonth = {jan},\narticleno = {31},\nnumpages = {31},\nkeywords = {concurrency, equivalence, predictive analysis, reads-from, reduction}\n}","doi":"10.1145/3632873"}},"ang-mathur-pattern-2024":{"title":"Predictive Monitoring against Pattern Regular Languages","taxon":"Reference","tags":["racepred","trace","paper"],"route":"ang-mathur-pattern-2024.xml","metas":{"bibtex":"@Article{10.1145/3632915,\nauthor = {Ang, Zhendong and Mathur, Umang},\ntitle = {Predictive Monitoring against Pattern Regular Languages},\nyear = {2024},\nissue_date = {January 2024},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {8},\nnumber = {POPL},\nurl = {https://doi.org/10.1145/3632915},\ndoi = {10.1145/3632915},\nabstract = {While current bug detection techniques for concurrent software focus on unearthing low-level issues such as data races or deadlocks, they often fall short of discovering more intricate temporal behaviours that can arise even in the absence of such low-level issues. In this paper, we focus on the problem of dynamically analysing concurrent software against high-level temporal specifications such as LTL. Existing techniques for runtime monitoring against such specifications are primarily designed for sequential software and remain inadequate in the presence of concurrency — violations may be observed only in intricate thread interleavings, requiring many re-runs of the underlying software in conjunction with the analysis. Towards this, we study the problem of predictive runtime monitoring, inspired by the analogous problem of predictive data race detection studied extensively recently. The predictive runtime monitoring question asks, given an execution σ, if it can be soundly reordered to expose violations of a specification. In general, this problem may become easily intractable when either the specifications or the notion of reorderings used is complex. In this paper, we focus on specifications that are given in regular languages. Our notion of reorderings is trace equivalence, where an execution is considered a reordering of another if it can be obtained from the latter by successively commuting adjacent independent actions. We first show that, even in this simplistic setting, the problem of predictive monitoring admits a super-linear lower bound of O(nα), where n is the number of events in the execution, and α is a parameter describing the degree of commutativity, and typically corresponds to the number of threads in the execution. As a result, predictive runtime monitoring even in this setting is unlikely to be efficiently solvable, unlike in the non-predictive setting where the problem can be checked using a deterministic finite automaton (and thus, a constant-space streaming linear-time algorithm). Towards this, we identify a sub-class of regular languages, called pattern languages (and their extension generalized pattern languages). Pattern languages can naturally express specific ordering of some number of (labelled) events, and have been inspired by popular empirical hypotheses underlying many concurrency bug detection approaches such as the “small bug depth” hypothesis. More importantly, we show that for pattern (and generalized pattern) languages, the predictive monitoring problem can be solved using a constant-space streaming linear-time algorithm. We implement and evaluate our algorithm PatternTrack on benchmarks from the literature and show that it is effective in monitoring large-scale applications.},\njournal = {Proc. ACM Program. Lang.},\nmonth = {jan},\narticleno = {73},\nnumpages = {35},\nkeywords = {complexity, concurrency, dynamic analysis, predictive monitoring}\n}","doi":"10.1145/3632915"}},"thokair-zhang-mathur-viswanathan-rpt-2023":{"title":"Dynamic Race Detection with O(1) Samples","taxon":"Reference","tags":["racepred","sampling-race","paper"],"route":"thokair-zhang-mathur-viswanathan-rpt-2023.xml","metas":{"bibtex":"@Article{10.1145/3571238,\nauthor = {Thokair, Mosaad Al and Zhang, Minjian and Mathur, Umang and Viswanathan, Mahesh},\ntitle = {Dynamic Race Detection with O(1) Samples},\nyear = {2023},\nissue_date = {January 2023},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {7},\nnumber = {POPL},\nurl = {https://doi.org/10.1145/3571238},\ndoi = {10.1145/3571238},\nabstract = {Happens before-based dynamic analysis is the go-to technique for detecting data races in large scale software projects due to the absence of false positive reports. However, such analyses are expensive since they employ expensive vector clock updates at each event, rendering them usable only for in-house testing. In this paper, we present a sampling-based, randomized race detector that processes only constantly many events of the input trace even in the worst case. This is the first sub-linear time (i.e., running in o(n) time where n is the length of the trace) dynamic race detection algorithm; previous sampling based approaches like  run in linear time (i.e., O(n)). Our algorithm is a property tester for -race detection — it is sound in that it never reports any false positive, and on traces that are far, with respect to hamming distance, from any race-free trace, the algorithm detects an -race with high probability. Our experimental evaluation of the algorithm and its comparison with state-of-the-art deterministic and sampling based race detectors shows that the algorithm does indeed have significantly low running time, and detects races quite often.},\njournal = {Proc. ACM Program. Lang.},\nmonth = {jan},\narticleno = {45},\nnumpages = {30},\nkeywords = {Concurrency - Shared memory, Dynamic program analysis, Happens-before race detection, Property testing}\n}","doi":"10.1145/3632915"}},"mathur-pavlogiannis-tunç-viswanathan-treeclocks-2022":{"title":"A tree clock data structure for causal orderings in concurrent executions","taxon":"Reference","tags":["racepred","paper"],"route":"mathur-pavlogiannis-tunç-viswanathan-treeclocks-2022.xml","metas":{"bibtex":"@Inproceedings{10.1145/3503222.3507734,\nauthor = {Mathur, Umang and Pavlogiannis, Andreas and Tun\\c{c}, H\\\"{u}nkar Can and Viswanathan, Mahesh},\ntitle = {A tree clock data structure for causal orderings in concurrent executions},\nyear = {2022},\nisbn = {9781450392051},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3503222.3507734},\ndoi = {10.1145/3503222.3507734},\nabstract = {Dynamic techniques are a scalable and effective way to analyze concurrent programs. Instead of analyzing all behaviors of a program, these techniques detect errors by focusing on a single program execution. Often a crucial step in these techniques is to define a causal ordering between events in the execution, which is then computed using vector clocks, a simple data structure that stores logical times of threads. The two basic operations of vector clocks, namely join and copy, require Θ(k) time, where k is the number of threads. Thus they are a computational bottleneck when k is large. In this work, we introduce tree clocks, a new data structure that replaces vector clocks for computing causal orderings in program executions. Joining and copying tree clocks takes time that is roughly proportional to the number of entries being modified, and hence the two operations do not suffer the a-priori Θ(k) cost per application. We show that when used to compute the classic happens-before (HB) partial order, tree clocks are optimal, in the sense that no other data structure can lead to smaller asymptotic running time. Moreover, we demonstrate that tree clocks can be used to compute other partial orders, such as schedulable-happens-before (SHB) and the standard Mazurkiewicz (MAZ) partial order, and thus are a versatile data structure. Our experiments show that just by replacing vector clocks with tree clocks, the computation becomes from 2.02 \\texttimes{} faster (MAZ) to 2.66 \\texttimes{} (SHB) and 2.97 \\texttimes{} (HB) on average per benchmark. These results illustrate that tree clocks have the potential to become a standard data structure with wide applications in concurrent analyses.},\nbooktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},\npages = {710–725},\nnumpages = {16},\nkeywords = {concurrency, dynamic analyses, happens-before, vector clocks},\nlocation = {Lausanne, Switzerland},\nseries = {ASPLOS '22}\n}","doi":"10.1145/3503222.3507734"}},"mathur-pavlogiannis-2021-asplos":{"title":"Dynamic Data-Race Prediction : Fundamentals, Theory and Practice","taxon":"Reference","tags":["talk","racepred","trace"],"route":"mathur-pavlogiannis-2021-asplos.xml","metas":{"external":"Https://www.youtube.com/watch?v=B6q2NQ5Tp2I","venue":"ASPLOS 2021 Tutorial"}},"mathur-pavlogiannis-2021-popl":{"title":"Dynamic Data-Race Prediction: Fundamentals, Theory and Practice","taxon":"Reference","tags":["talk","racepred","trace"],"route":"mathur-pavlogiannis-2021-popl.xml","metas":{"external":"Https://www.youtube.com/watch?v=5AZIQFeluIY","venue":"POPL 2021 Tutorial"}},"mathur-pavlogiannis-viswanathan-syncp-2021":{"title":"Optimal prediction of synchronization-preserving races","taxon":"Reference","tags":["racepred","trace","paper"],"route":"mathur-pavlogiannis-viswanathan-syncp-2021.xml","metas":{"bibtex":"@Article{10.1145/3434317,\nauthor = {Mathur, Umang and Pavlogiannis, Andreas and Viswanathan, Mahesh},\ntitle = {Optimal prediction of synchronization-preserving races},\nyear = {2021},\nissue_date = {January 2021},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {5},\nnumber = {POPL},\nurl = {https://doi.org/10.1145/3434317},\ndoi = {10.1145/3434317},\nabstract = {Concurrent programs are notoriously hard to write correctly, as scheduling nondeterminism introduces subtle errors that are both hard to detect and to reproduce. The most common concurrency errors are (data) races, which occur when memory-conflicting actions are executed concurrently. Consequently, considerable effort has been made towards developing efficient techniques for race detection. The most common approach is dynamic race prediction: given an observed, race-free trace σ of a concurrent program, the task is to decide whether events of σ can be correctly reordered to a trace σ* that witnesses a race hidden in σ. In this work we introduce the notion of sync(hronization)-preserving races. A sync-preserving race occurs in σ when there is a witness σ* in which synchronization operations (e.g., acquisition and release of locks) appear in the same order as in σ. This is a broad definition that strictly subsumes the famous notion of happens-before races. Our main results are as follows. First, we develop a sound and complete algorithm for predicting sync-preserving races. For moderate values of parameters like the number of threads, the algorithm runs in \\~{O}(N) time and space, where N is the length of the trace σ. Second, we show that the problem has a Ω(N/log2 N) space lower bound, and thus our algorithm is essentially time and space optimal. Third, we show that predicting races with even just a single reversal of two sync operations is NP-complete and even W1-hard when parameterized by the number of threads. Thus, sync-preservation characterizes exactly the tractability boundary of race prediction, and our algorithm is nearly optimal for the tractable side. Our experiments show that our algorithm is fast in practice, while sync-preservation characterizes races often missed by state-of-the-art methods.},\njournal = {Proc. ACM Program. Lang.},\nmonth = {jan},\narticleno = {36},\nnumpages = {29},\nkeywords = {race detection, dynamic analysis, concurrency, complexity}\n}","doi":"10.1145/3434317"}},"mathur-pavlogiannis-viswanathan-2020":{"title":"The Complexity of Dynamic Data Race Prediction","taxon":"Reference","tags":["racepred","trace","paper"],"route":"mathur-pavlogiannis-viswanathan-2020.xml","metas":{"bibtex":"@Inproceedings{10.1145/3373718.3394783,\nauthor = {Mathur, Umang and Pavlogiannis, Andreas and Viswanathan, Mahesh},\ntitle = {The Complexity of Dynamic Data Race Prediction},\nyear = {2020},\nisbn = {9781450371049},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3373718.3394783},\ndoi = {10.1145/3373718.3394783},\nabstract = {Writing concurrent programs is notoriously hard due to scheduling non-determinism. The most common concurrency bugs are data races, which are accesses to a shared resource that can be executed concurrently. Dynamic data-race prediction is the most standard technique for detecting data races: given an observed, data-race-free trace t, the task is to determine whether t can be reordered to a trace t* that exposes a data-race. Although the problem has received significant practical attention for over three decades, its complexity has remained elusive. In this work, we address this lacuna, identifying sources of intractability and conditions under which the problem is efficiently solvable. Given a trace t of size n over k threads, our main results are as follows.First, we establish a general O(k · n2·(k-1) upper-bound, as well as an O(nk) upper-bound when certain parameters of t are constant. In addition, we show that the problem is NP-hard and even W[1]-hard parameterized by k, and thus unlikely to be fixed-parameter tractable. Second, we study the problem over acyclic communication topologies, such as server-clients hierarchies. We establish an O(k2 · d · n2 · log n) upper-bound, where d is the number of shared variables accessed in t. In addition, we show that even for traces with k = 2 threads, the problem has no O(n2-ϵ) algorithm under the Orthogonal Vectors conjecture. Since any trace with 2 threads defines an acyclic topology, our upper-bound for this case is optimal up to polynomial improvements for up to moderate values of k and d. Finally, motivated by existing heuristics, we study a distance-bounded version of the problem, where the task is to expose a data race by a witness trace that is similar to t. We develop an algorithm that works in O(n) time when certain parameters of t are constant.},\nbooktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},\npages = {713–727},\nnumpages = {15},\nkeywords = {Complexity, Data Race Prediction},\nlocation = {Saarbr\\\"{u}cken, Germany},\nseries = {LICS '20}\n}","doi":"10.1145/3373718.3394783"}},"pavlogiannis-m2-2019":{"title":"Fast, sound, and effectively complete dynamic race prediction","taxon":"Reference","tags":["racepred","trace","paper"],"route":"pavlogiannis-m2-2019.xml","metas":{"bibtex":"@Article{10.1145/3371085,\nauthor = {Pavlogiannis, Andreas},\ntitle = {Fast, sound, and effectively complete dynamic race prediction},\nyear = {2019},\nissue_date = {January 2020},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {4},\nnumber = {POPL},\nurl = {https://doi.org/10.1145/3371085},\ndoi = {10.1145/3371085},\nabstract = {Writing concurrent programs is highly error-prone due to the nondeterminism in interprocess communication. The most reliable indicators of errors in concurrency are data races, which are accesses to a shared resource that can be executed concurrently. We study the problem of predicting data races in lock-based concurrent programs. The input consists of a concurrent trace t, and the task is to determine all pairs of events of t that constitute a data race. The problem lies at the heart of concurrent verification and has been extensively studied for over three decades. However, existing polynomial-time sound techniques are highly incomplete and can miss simple races. In this work we develop M2: a new polynomial-time algorithm for this problem, which has no false positives. In addition, our algorithm is complete for input traces that consist of two processes, i.e., it provably detects all races in the trace. We also develop sufficient criteria for detecting completeness dynamically in cases of more than two processes. We make an experimental evaluation of our algorithm on a challenging set of benchmarks taken from recent literature on the topic. Our algorithm soundly reports hundreds of real races, many of which are missed by existing methods. In addition, using our dynamic completeness criteria, M2 concludes that it has detected all races in the benchmark set, hence the reports are both sound and complete. Finally, its running times are comparable, and often smaller than the theoretically fastest, yet highly incomplete, existing methods. To our knowledge, M2 is the first sound algorithm that achieves such a level of performance on both running time and completeness of the reported races.},\njournal = {Proc. ACM Program. Lang.},\nmonth = {dec},\narticleno = {17},\nnumpages = {29},\nkeywords = {race detection, predictive analyses, concurrency}\n}","doi":"10.1145/3371085"}},"mathur-kini-viswanathan-shb-2018":{"title":"What happens-after the first race? Enhancing the predictive power of happens-before based dynamic race detection","taxon":"Reference","tags":["racepred","trace","paper"],"route":"mathur-kini-viswanathan-shb-2018.xml","metas":{"bibtex":"@Article{10.1145/3276515,\nauthor = {Mathur, Umang and Kini, Dileep and Viswanathan, Mahesh},\ntitle = {What happens-after the first race? enhancing the predictive power of happens-before based dynamic race detection},\nyear = {2018},\nissue_date = {November 2018},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {2},\nnumber = {OOPSLA},\nurl = {https://doi.org/10.1145/3276515},\ndoi = {10.1145/3276515},\nabstract = {Dynamic race detection is the problem of determining if an observed program execution reveals the presence of a data race in a program. The classical approach to solving this problem is to detect if there is a pair of conflicting memory accesses that are unordered by Lamport’s happens-before (HB) relation. HB based race detection is known to not report false positives, i.e., it is sound. However, the soundness guarantee of HB only promises that the first pair of unordered, conflicting events is a schedulable data race. That is, there can be pairs of HB-unordered conflicting data accesses that are not schedulable races because there is no reordering of the events of the execution, where the events in race can be executed immediately after each other. We introduce a new partial order, called schedulable happens-before (SHB) that exactly characterizes the pairs of schedulable data races — every pair of conflicting data accesses that are identified by SHB can be scheduled, and every HB-race that can be scheduled is identified by SHB. Thus, the SHB partial order is truly sound. We present a linear time, vector clock algorithm to detect schedulable races using SHB. Our experiments demonstrate the value of our algorithm for dynamic race detection — SHB incurs only little performance overhead and can scale to executions from real-world software applications without compromising soundness.},\njournal = {Proc. ACM Program. Lang.},\nmonth = {oct},\narticleno = {145},\nnumpages = {29},\nkeywords = {Concurrency, Dynamic Program Analysis, Happens-Before, Race Detection, Soundness}\n}","doi":"10.1145/3276515"}},"kini-mathur-viswanathan-wcp-2017":{"title":"Dynamic race prediction in linear time","taxon":"Reference","tags":["racepred","paper","trace"],"route":"kini-mathur-viswanathan-wcp-2017.xml","metas":{"bibtex":"@Inproceedings{10.1145/3062341.3062374,\nauthor = {Kini, Dileep and Mathur, Umang and Viswanathan, Mahesh},\ntitle = {Dynamic race prediction in linear time},\nyear = {2017},\nisbn = {9781450349888},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3062341.3062374},\ndoi = {10.1145/3062341.3062374},\nabstract = {Writing reliable concurrent software remains a huge challenge for today's programmers. Programmers rarely reason about their code by explicitly considering different possible inter-leavings of its execution. We consider the problem of detecting data races from individual executions in a sound manner. The classical approach to solving this problem has been to use Lamport's happens-before (HB) relation. Until now HB remains the only approach that runs in linear time. Previous efforts in improving over HB such as causally-precedes (CP) and maximal causal models fall short due to the fact that they are not implementable efficiently and hence have to compromise on their race detecting ability by limiting their techniques to bounded sized fragments of the execution. We present a new relation weak-causally-precedes (WCP) that is provably better than CP in terms of being able to detect more races, while still remaining sound. Moreover, it admits a linear time algorithm which works on the entire execution without having to fragment it.},\nbooktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},\npages = {157–170},\nnumpages = {14},\nkeywords = {Race Prediction, Online Algorithm, Concurrency},\nlocation = {Barcelona, Spain},\nseries = {PLDI 2017}\n}\n\n@article{10.1145/3140587.3062374,\nauthor = {Kini, Dileep and Mathur, Umang and Viswanathan, Mahesh},\ntitle = {Dynamic race prediction in linear time},\nyear = {2017},\nissue_date = {June 2017},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {52},\nnumber = {6},\nissn = {0362-1340},\nurl = {https://doi.org/10.1145/3140587.3062374},\ndoi = {10.1145/3140587.3062374},\nabstract = {Writing reliable concurrent software remains a huge challenge for today's programmers. Programmers rarely reason about their code by explicitly considering different possible inter-leavings of its execution. We consider the problem of detecting data races from individual executions in a sound manner. The classical approach to solving this problem has been to use Lamport's happens-before (HB) relation. Until now HB remains the only approach that runs in linear time. Previous efforts in improving over HB such as causally-precedes (CP) and maximal causal models fall short due to the fact that they are not implementable efficiently and hence have to compromise on their race detecting ability by limiting their techniques to bounded sized fragments of the execution. We present a new relation weak-causally-precedes (WCP) that is provably better than CP in terms of being able to detect more races, while still remaining sound. Moreover, it admits a linear time algorithm which works on the entire execution without having to fragment it.},\njournal = {SIGPLAN Not.},\nmonth = {jun},\npages = {157–170},\nnumpages = {14},\nkeywords = {Race Prediction, Online Algorithm, Concurrency}\n}","doi":"10.1145/3062341.3062374"}},"huang-meredith-rosu-rvpredict-2014":{"title":"Maximal sound predictive race detection with control flow abstraction","taxon":"Reference","tags":["racepred","trace","paper"],"route":"huang-meredith-rosu-rvpredict-2014.xml","metas":{"bibtex":"@Inproceedings{10.1145/2594291.2594315,\nauthor = {Huang, Jeff and Meredith, Patrick O'Neil and Rosu, Grigore},\ntitle = {Maximal sound predictive race detection with control flow abstraction},\nyear = {2014},\nisbn = {9781450327848},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2594291.2594315},\ndoi = {10.1145/2594291.2594315},\nabstract = {Despite the numerous static and dynamic program analysis techniques in the literature, data races remain one of the most common bugs in modern concurrent software. Further, the techniques that do exist either have limited detection capability or are unsound, meaning that they report false positives. We present a sound race detection technique that achieves a provably higher detection capability than existing sound techniques. A key insight of our technique is the inclusion of abstracted control flow information into the execution model, which increases the space of the causal model permitted by classical happens-before or causally-precedes based detectors. By encoding the control flow and a minimal set of feasibility constraints as a group of first-order logic formulae, we formulate race detection as a constraint solving problem. Moreover, we formally prove that our formulation achieves the maximal possible detection capability for any sound dynamic race detector with respect to the same input trace under the sequential consistency memory model. We demonstrate via extensive experimentation that our technique detects more races than the other state-of-the-art sound race detection techniques, and that it is scalable to executions of real world concurrent applications with tens of millions of critical events. These experiments also revealed several previously unknown races in real systems (e.g., Eclipse) that have been confirmed or fixed by the developers. Our tool is also adopted by Eclipse developers.},\nbooktitle = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},\npages = {337–348},\nnumpages = {12},\nkeywords = {control flow, data race, maximal sound, prediction},\nlocation = {Edinburgh, United Kingdom},\nseries = {PLDI '14}\n}\n\n@article{10.1145/2666356.2594315,\nauthor = {Huang, Jeff and Meredith, Patrick O'Neil and Rosu, Grigore},\ntitle = {Maximal sound predictive race detection with control flow abstraction},\nyear = {2014},\nissue_date = {June 2014},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {49},\nnumber = {6},\nissn = {0362-1340},\nurl = {https://doi.org/10.1145/2666356.2594315},\ndoi = {10.1145/2666356.2594315},\nabstract = {Despite the numerous static and dynamic program analysis techniques in the literature, data races remain one of the most common bugs in modern concurrent software. Further, the techniques that do exist either have limited detection capability or are unsound, meaning that they report false positives. We present a sound race detection technique that achieves a provably higher detection capability than existing sound techniques. A key insight of our technique is the inclusion of abstracted control flow information into the execution model, which increases the space of the causal model permitted by classical happens-before or causally-precedes based detectors. By encoding the control flow and a minimal set of feasibility constraints as a group of first-order logic formulae, we formulate race detection as a constraint solving problem. Moreover, we formally prove that our formulation achieves the maximal possible detection capability for any sound dynamic race detector with respect to the same input trace under the sequential consistency memory model. We demonstrate via extensive experimentation that our technique detects more races than the other state-of-the-art sound race detection techniques, and that it is scalable to executions of real world concurrent applications with tens of millions of critical events. These experiments also revealed several previously unknown races in real systems (e.g., Eclipse) that have been confirmed or fixed by the developers. Our tool is also adopted by Eclipse developers.},\njournal = {SIGPLAN Not.},\nmonth = {jun},\npages = {337–348},\nnumpages = {12},\nkeywords = {control flow, data race, maximal sound, prediction}\n}","doi":"10.1145/2594291.2594315"}},"smaragdakis-cp-2012":{"title":"Sound predictive race detection in polynomial time","taxon":"Reference","tags":["racepred","trace","paper"],"route":"smaragdakis-cp-2012.xml","metas":{"bibtex":"@Inproceedings{10.1145/2103656.2103702,\nauthor = {Smaragdakis, Yannis and Evans, Jacob and Sadowski, Caitlin and Yi, Jaeheon and Flanagan, Cormac},\ntitle = {Sound predictive race detection in polynomial time},\nyear = {2012},\nisbn = {9781450310833},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2103656.2103702},\ndoi = {10.1145/2103656.2103702},\nabstract = {Data races are among the most reliable indicators of programming errors in concurrent software. For at least two decades, Lamport's happens-before (HB) relation has served as the standard test for detecting races--other techniques, such as lockset-based approaches, fail to be sound, as they may falsely warn of races. This work introduces a new relation, causally-precedes (CP), which generalizes happens-before to observe more races without sacrificing soundness. Intuitively, CP tries to capture the concept of happens-before ordered events that must occur in the observed order for the program to observe the same values. What distinguishes CP from past predictive race detection approaches (which also generalize an observed execution to detect races in other plausible executions) is that CP-based race detection is both sound and of polynomial complexity. We demonstrate that the unique aspects of CP result in practical benefit. Applying CP to real-world programs, we successfully analyze server-level applications (e.g., Apache FtpServer) and show that traces longer than in past predictive race analyses can be analyzed in mere seconds to a few minutes. For these programs, CP race detection uncovers races that are hard to detect by repeated execution and HB race detection: a single run of CP race detection produces several races not discovered by 10 separate rounds of happens-before race detection.},\nbooktitle = {Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},\npages = {387–400},\nnumpages = {14},\nkeywords = {dynamic analysis, happens-before, race detection},\nlocation = {Philadelphia, PA, USA},\nseries = {POPL '12}\n}\n\n@article{10.1145/2103621.2103702,\nauthor = {Smaragdakis, Yannis and Evans, Jacob and Sadowski, Caitlin and Yi, Jaeheon and Flanagan, Cormac},\ntitle = {Sound predictive race detection in polynomial time},\nyear = {2012},\nissue_date = {January 2012},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {47},\nnumber = {1},\nissn = {0362-1340},\nurl = {https://doi.org/10.1145/2103621.2103702},\ndoi = {10.1145/2103621.2103702},\nabstract = {Data races are among the most reliable indicators of programming errors in concurrent software. For at least two decades, Lamport's happens-before (HB) relation has served as the standard test for detecting races--other techniques, such as lockset-based approaches, fail to be sound, as they may falsely warn of races. This work introduces a new relation, causally-precedes (CP), which generalizes happens-before to observe more races without sacrificing soundness. Intuitively, CP tries to capture the concept of happens-before ordered events that must occur in the observed order for the program to observe the same values. What distinguishes CP from past predictive race detection approaches (which also generalize an observed execution to detect races in other plausible executions) is that CP-based race detection is both sound and of polynomial complexity. We demonstrate that the unique aspects of CP result in practical benefit. Applying CP to real-world programs, we successfully analyze server-level applications (e.g., Apache FtpServer) and show that traces longer than in past predictive race analyses can be analyzed in mere seconds to a few minutes. For these programs, CP race detection uncovers races that are hard to detect by repeated execution and HB race detection: a single run of CP race detection produces several races not discovered by 10 separate rounds of happens-before race detection.},\njournal = {SIGPLAN Not.},\nmonth = {jan},\npages = {387–400},\nnumpages = {14},\nkeywords = {dynamic analysis, happens-before, race detection}\n}","doi":"10.1145/2103656.2103702"}},"bond-coons-mckinley-pacer-2010":{"title":"PACER: proportional detection of data races","taxon":"Reference","tags":["racepred","sampling-race","paper"],"route":"bond-coons-mckinley-pacer-2010.xml","metas":{"bibtex":"@Article{10.1145/1809028.1806626,\nauthor = {Bond, Michael D. and Coons, Katherine E. and McKinley, Kathryn S.},\ntitle = {PACER: proportional detection of data races},\nyear = {2010},\nissue_date = {June 2010},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {45},\nnumber = {6},\nissn = {0362-1340},\nurl = {https://doi.org/10.1145/1809028.1806626},\ndoi = {10.1145/1809028.1806626},\nabstract = {Data races indicate serious concurrency bugs such as order, atomicity, and sequential consistency violations. Races are difficult to find and fix, often manifesting only after deployment. The frequency and unpredictability of these bugs will only increase as software adds parallelism to exploit multicore hardware. Unfortunately, sound and precise race detectors slow programs by factors of eight or more and do not scale to large numbers of threads.This paper presents a precise, low-overhead sampling-based data race detector called Pacer. PACER makes a proportionality guarantee: it detects any race at a rate equal to the sampling rate, by finding races whose first access occurs during a global sampling period. During sampling, PACER tracks all accesses using the dynamically sound and precise FastTrack algorithm. In nonsampling periods, Pacer discards sampled access information that cannot be part of a reported race, and Pacer simplifies tracking of the happens-before relationship, yielding near-constant, instead of linear, overheads. Experimental results confirm our theoretical guarantees. PACER reports races in proportion to the sampling rate. Its time and space overheads scale with the sampling rate, and sampling rates of 1-3\\% yield overheads low enough to consider in production software. The resulting system provides a \"get what you pay for\" approach that is suitable for identifying real, hard-to-reproduce races in deployed systems.},\njournal = {SIGPLAN Not.},\nmonth = {jun},\npages = {255–268},\nnumpages = {14},\nkeywords = {bugs, concurrency, data races, sampling}\n}\n\n@inproceedings{10.1145/1806596.1806626,\nauthor = {Bond, Michael D. and Coons, Katherine E. and McKinley, Kathryn S.},\ntitle = {PACER: proportional detection of data races},\nyear = {2010},\nisbn = {9781450300193},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/1806596.1806626},\ndoi = {10.1145/1806596.1806626},\nabstract = {Data races indicate serious concurrency bugs such as order, atomicity, and sequential consistency violations. Races are difficult to find and fix, often manifesting only after deployment. The frequency and unpredictability of these bugs will only increase as software adds parallelism to exploit multicore hardware. Unfortunately, sound and precise race detectors slow programs by factors of eight or more and do not scale to large numbers of threads.This paper presents a precise, low-overhead sampling-based data race detector called Pacer. PACER makes a proportionality guarantee: it detects any race at a rate equal to the sampling rate, by finding races whose first access occurs during a global sampling period. During sampling, PACER tracks all accesses using the dynamically sound and precise FastTrack algorithm. In nonsampling periods, Pacer discards sampled access information that cannot be part of a reported race, and Pacer simplifies tracking of the happens-before relationship, yielding near-constant, instead of linear, overheads. Experimental results confirm our theoretical guarantees. PACER reports races in proportion to the sampling rate. Its time and space overheads scale with the sampling rate, and sampling rates of 1-3\\% yield overheads low enough to consider in production software. The resulting system provides a \"get what you pay for\" approach that is suitable for identifying real, hard-to-reproduce races in deployed systems.},\nbooktitle = {Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation},\npages = {255–268},\nnumpages = {14},\nkeywords = {bugs, concurrency, data races, sampling},\nlocation = {Toronto, Ontario, Canada},\nseries = {PLDI '10}\n}","doi":"10.1145/1809028.1806626"}},"serebryany-iskhodzhanov-tsan-2009":{"title":"ThreadSanitizer: data race detection in practice","taxon":"Reference","tags":["racepred","paper"],"route":"serebryany-iskhodzhanov-tsan-2009.xml","metas":{"bibtex":"@Inproceedings{10.1145/1791194.1791203,\nauthor = {Serebryany, Konstantin and Iskhodzhanov, Timur},\ntitle = {ThreadSanitizer: data race detection in practice},\nyear = {2009},\nisbn = {9781605587936},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/1791194.1791203},\ndoi = {10.1145/1791194.1791203},\nabstract = {Data races are a particularly unpleasant kind of threading bugs. They are hard to find and reproduce -- you may not observe a bug during the entire testing cycle and will only see it in production as rare unexplainable failures. This paper presents ThreadSanitizer -- a dynamic detector of data races. We describe the hybrid algorithm (based on happens-before and locksets) used in the detector. We introduce what we call dynamic annotations -- a sort of race detection API that allows a user to inform the detector about any tricky synchronization in the user program. Various practical aspects of using ThreadSanitizer for testing multithreaded C++ code at Google are also discussed.},\nbooktitle = {Proceedings of the Workshop on Binary Instrumentation and Applications},\npages = {62–71},\nnumpages = {10},\nkeywords = {testing, dynamic data race detection, concurrency bugs, Valgrind},\nlocation = {New York, New York, USA},\nseries = {WBIA '09}\n}","doi":"10.1145/1791194.1791203"}},"flanagan-freund-fasttrack-2009":{"title":"FastTrack: efficient and precise dynamic race detection","taxon":"Reference","tags":["racepred","paper"],"route":"flanagan-freund-fasttrack-2009.xml","metas":{"bibtex":"@Article{10.1145/1543135.1542490,\nauthor = {Flanagan, Cormac and Freund, Stephen N.},\ntitle = {FastTrack: efficient and precise dynamic race detection},\nyear = {2009},\nissue_date = {June 2009},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {44},\nnumber = {6},\nissn = {0362-1340},\nurl = {https://doi.org/10.1145/1543135.1542490},\ndoi = {10.1145/1543135.1542490},\nabstract = {begin{abstract}Multithreaded programs are notoriously prone to race conditions. Prior work on dynamic race detectors includes fast but imprecise race detectors that report false alarms, as well as slow but precise race detectors that never report false alarms. The latter typically use expensive vector clock operations that require time linear in the number of program threads.This paper exploits the insight that the full generality of vector clocks is unnecessary in most cases. That is, we can replace heavyweight vector clocks with an adaptive lightweight representation that, for almost all operations of the target program, requires only constant space and supports constant-time operations. This representation change significantly improves time and space performance, with no loss in precision.Experimental results on Java benchmarks including the Eclipse development environment show that our FastTrack race detector is an order of magnitude faster than a traditional vector-clock race detector, and roughly twice as fast as the high-performance DJIT+ algorithm. FastTrack is even comparable in speed to Eraser on our Java benchmarks, while never reporting false alarms.},\njournal = {SIGPLAN Not.},\nmonth = {jun},\npages = {121–133},\nnumpages = {13},\nkeywords = {race conditions, dynamic analysis, concurrency}\n}\n\n@inproceedings{10.1145/1542476.1542490,\nauthor = {Flanagan, Cormac and Freund, Stephen N.},\ntitle = {FastTrack: efficient and precise dynamic race detection},\nyear = {2009},\nisbn = {9781605583921},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/1542476.1542490},\ndoi = {10.1145/1542476.1542490},\nabstract = {begin{abstract}Multithreaded programs are notoriously prone to race conditions. Prior work on dynamic race detectors includes fast but imprecise race detectors that report false alarms, as well as slow but precise race detectors that never report false alarms. The latter typically use expensive vector clock operations that require time linear in the number of program threads.This paper exploits the insight that the full generality of vector clocks is unnecessary in most cases. That is, we can replace heavyweight vector clocks with an adaptive lightweight representation that, for almost all operations of the target program, requires only constant space and supports constant-time operations. This representation change significantly improves time and space performance, with no loss in precision.Experimental results on Java benchmarks including the Eclipse development environment show that our FastTrack race detector is an order of magnitude faster than a traditional vector-clock race detector, and roughly twice as fast as the high-performance DJIT+ algorithm. FastTrack is even comparable in speed to Eraser on our Java benchmarks, while never reporting false alarms.},\nbooktitle = {Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation},\npages = {121–133},\nnumpages = {13},\nkeywords = {race conditions, dynamic analysis, concurrency},\nlocation = {Dublin, Ireland},\nseries = {PLDI '09}\n}","doi":"10.1145/1543135.1542490"}},"marino-musuvathi-narayanasamy-literace-2009":{"title":"LiteRace: effective sampling for lightweight data-race detection","taxon":"Reference","tags":["racepred","sampling-race","paper"],"route":"marino-musuvathi-narayanasamy-literace-2009.xml","metas":{"bibtex":"@Inproceedings{10.1145/1542476.1542491,\nauthor = {Marino, Daniel and Musuvathi, Madanlal and Narayanasamy, Satish},\ntitle = {LiteRace: effective sampling for lightweight data-race detection},\nyear = {2009},\nisbn = {9781605583921},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/1542476.1542491},\ndoi = {10.1145/1542476.1542491},\nabstract = {Data races are one of the most common and subtle causes of pernicious concurrency bugs. Static techniques for preventing data races are overly conservative and do not scale well to large programs. Past research has produced several dynamic data race detectors that can be applied to large programs. They are precise in the sense that they only report actual data races. However, dynamic data race detectors incur a high performance overhead, slowing down a program's execution by an order of magnitude.In this paper we present LiteRace, a very lightweight data race detector that samples and analyzes only selected portions of a program's execution. We show that it is possible to sample a multithreaded program at a low frequency, and yet, find infrequently occurring data races. We implemented LiteRace using Microsoft's Phoenix compiler. Our experiments with several Microsoft programs, Apache, and Firefox show that LiteRace is able to find more than 70\\% of data races by sampling less than 2\\% of memory accesses in a given program execution.},\nbooktitle = {Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation},\npages = {134–143},\nnumpages = {10},\nkeywords = {concurrency bugs, dynamic data race detection, sampling},\nlocation = {Dublin, Ireland},\nseries = {PLDI '09}\n}\n\n@article{10.1145/1543135.1542491,\nauthor = {Marino, Daniel and Musuvathi, Madanlal and Narayanasamy, Satish},\ntitle = {LiteRace: effective sampling for lightweight data-race detection},\nyear = {2009},\nissue_date = {June 2009},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {44},\nnumber = {6},\nissn = {0362-1340},\nurl = {https://doi.org/10.1145/1543135.1542491},\ndoi = {10.1145/1543135.1542491},\nabstract = {Data races are one of the most common and subtle causes of pernicious concurrency bugs. Static techniques for preventing data races are overly conservative and do not scale well to large programs. Past research has produced several dynamic data race detectors that can be applied to large programs. They are precise in the sense that they only report actual data races. However, dynamic data race detectors incur a high performance overhead, slowing down a program's execution by an order of magnitude.In this paper we present LiteRace, a very lightweight data race detector that samples and analyzes only selected portions of a program's execution. We show that it is possible to sample a multithreaded program at a low frequency, and yet, find infrequently occurring data races. We implemented LiteRace using Microsoft's Phoenix compiler. Our experiments with several Microsoft programs, Apache, and Firefox show that LiteRace is able to find more than 70\\% of data races by sampling less than 2\\% of memory accesses in a given program execution.},\njournal = {SIGPLAN Not.},\nmonth = {jun},\npages = {134–143},\nnumpages = {10},\nkeywords = {concurrency bugs, dynamic data race detection, sampling}\n}","doi":"10.1145/1542476.1542491"}},"elmas-goldilocks-2007":{"title":"Goldilocks: a race and transaction-aware java runtime","taxon":"Reference","tags":["racepred","paper"],"route":"elmas-goldilocks-2007.xml","metas":{"bibtex":"@Article{10.1145/1273442.1250762,\nauthor = {Elmas, Tayfun and Qadeer, Shaz and Tasiran, Serdar},\ntitle = {Goldilocks: a race and transaction-aware java runtime},\nyear = {2007},\nissue_date = {June 2007},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {42},\nnumber = {6},\nissn = {0362-1340},\nurl = {https://doi.org/10.1145/1273442.1250762},\ndoi = {10.1145/1273442.1250762},\nabstract = {Data races often result in unexpected and erroneous behavior. In addition to causing data corruption and leading programs to crash, the presence of data races complicates the semantics of an execution which might no longer be sequentially consistent. Motivated by these observations, we have designed and implemented a Java runtime system that monitors program executions and throws a DataRaceException when a data race is about to occur. Analogous to other runtime exceptions, the DataRaceException provides two key benefits. First, accesses causing race conditions are interruptedand handled before they cause errors that may be difficult to diagnose later. Second, if no DataRaceException is thrown in an execution, it is guaranteed to be sequentially consistent. This strong guarantee helps to rule out many concurrency-related possibilities as the cause of erroneous behavior. When a DataRaceException is caught, the operation, thread, or program causing it can be terminated gracefully. Alternatively, the DataRaceException can serve as a conflict-detection mechanism inoptimistic uses of concurrency.We start with the definition of data-race-free executions in the Java memory model. We generalize this definition to executions that use transactions in addition to locks and volatile variables for synchronization. We present a precise and efficient algorithm for dynamically verifying that an execution is free of data races. This algorithm generalizes the Goldilocks algorithm for data-race detectionby handling transactions and providing the ability to distinguish between read and write accesses. We have implemented our algorithm and the DataRaceException in the Kaffe Java Virtual Machine. We have evaluated our system on a variety of publicly available Java benchmarks and a few microbenchmarks that combine lock-based and transaction-based synchronization. Our experiments indicate that our implementation has reasonable overhead. Therefore, we believe that inaddition to being a debugging tool, the DataRaceException may be a viable mechanism to enforce the safety of executions of multithreaded Java programs.},\njournal = {SIGPLAN Not.},\nmonth = {jun},\npages = {245–255},\nnumpages = {11},\nkeywords = {Java runtime, data-race detection, runtime monitoring, software transactions}\n}\n\n@inproceedings{10.1145/1250734.1250762,\nauthor = {Elmas, Tayfun and Qadeer, Shaz and Tasiran, Serdar},\ntitle = {Goldilocks: a race and transaction-aware java runtime},\nyear = {2007},\nisbn = {9781595936332},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/1250734.1250762},\ndoi = {10.1145/1250734.1250762},\nabstract = {Data races often result in unexpected and erroneous behavior. In addition to causing data corruption and leading programs to crash, the presence of data races complicates the semantics of an execution which might no longer be sequentially consistent. Motivated by these observations, we have designed and implemented a Java runtime system that monitors program executions and throws a DataRaceException when a data race is about to occur. Analogous to other runtime exceptions, the DataRaceException provides two key benefits. First, accesses causing race conditions are interruptedand handled before they cause errors that may be difficult to diagnose later. Second, if no DataRaceException is thrown in an execution, it is guaranteed to be sequentially consistent. This strong guarantee helps to rule out many concurrency-related possibilities as the cause of erroneous behavior. When a DataRaceException is caught, the operation, thread, or program causing it can be terminated gracefully. Alternatively, the DataRaceException can serve as a conflict-detection mechanism inoptimistic uses of concurrency.We start with the definition of data-race-free executions in the Java memory model. We generalize this definition to executions that use transactions in addition to locks and volatile variables for synchronization. We present a precise and efficient algorithm for dynamically verifying that an execution is free of data races. This algorithm generalizes the Goldilocks algorithm for data-race detectionby handling transactions and providing the ability to distinguish between read and write accesses. We have implemented our algorithm and the DataRaceException in the Kaffe Java Virtual Machine. We have evaluated our system on a variety of publicly available Java benchmarks and a few microbenchmarks that combine lock-based and transaction-based synchronization. Our experiments indicate that our implementation has reasonable overhead. Therefore, we believe that inaddition to being a debugging tool, the DataRaceException may be a viable mechanism to enforce the safety of executions of multithreaded Java programs.},\nbooktitle = {Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation},\npages = {245–255},\nnumpages = {11},\nkeywords = {Java runtime, data-race detection, runtime monitoring, software transactions},\nlocation = {San Diego, California, USA},\nseries = {PLDI '07}\n}","doi":"10.1145/1273442.1250762"}},"pozniansky-schuster-djit+-2006":{"title":"MultiRace: efficient on-the-fly data race detection in multithreaded C++ programs","taxon":"Reference","tags":["racepred","paper"],"route":"pozniansky-schuster-djit+-2006.xml","metas":{"bibtex":"@Article{https://doi.org/10.1002/cpe.1064,\nauthor = {Pozniansky, Eli and Schuster, Assaf},\ntitle = {MultiRace: efficient on-the-fly data race detection in multithreaded C++ programs},\njournal = {Concurrency and Computation: Practice and Experience},\nvolume = {19},\nnumber = {3},\npages = {327-340},\nkeywords = {data race, concurrency, multithreading, instrumentation, synchronization},\ndoi = {https://doi.org/10.1002/cpe.1064},\nurl = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.1064},\neprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.1064},\nabstract = {Abstract Data race detection is highly essential for debugging multithreaded programs and assuring their correctness. Nevertheless, there is no single universal technique capable of handling the task efficiently, since the data race detection problem is computationally hard in the general case. Thus, all currently available tools, when applied to some general case program, usually result in excessive false alarms or in a large number of undetected races. Another major drawback of many currently available tools is that they are restricted, for performance reasons, to detection units of fixed size. Thus, they all suffer from the same problem—choosing a small unit might result in missing some of the data races, while choosing a large one might lead to false detection. We present a novel testing tool, called MultiRace, which combines improved versions of Djit and Lockset—two very powerful on-the-fly algorithms for dynamic detection of apparent data races. Both extended algorithms detect races in multithreaded programs that may execute on weak consistency systems, and may use two-way as well as global synchronization primitives. By employing novel technologies, MultiRace adjusts its detection to the native granularity of objects and variables in the program under examination. In order to monitor all accesses to each of the shared locations, MultiRace instruments the C++ source code of the program. It lets the user fine-tune the detection process, but otherwise is completely automatic and transparent. This paper describes the algorithms employed in MultiRace, gives highlights of its implementation issues, and suggests some optimizations. It shows that the overheads imposed by MultiRace are often much smaller (orders of magnitude) than those obtained by other existing tools. Copyright © 2006 John Wiley \\& Sons, Ltd.},\nyear = {2007}\n}","doi":"10.1002/Cpe.1064"}},"itzkovitz-djit-1999":{"title":"Toward Integration of Data Race Detection in DSM Systems","taxon":"Reference","tags":["racepred","paper"],"route":"itzkovitz-djit-1999.xml","metas":{"bibtex":"@Article{ITZKOVITZ1999180,\ntitle = {Toward Integration of Data Race Detection in DSM Systems},\njournal = {Journal of Parallel and Distributed Computing},\nvolume = {59},\nnumber = {2},\npages = {180-203},\nyear = {1999},\nissn = {0743-7315},\ndoi = {https://doi.org/10.1006/jpdc.1999.1574},\nurl = {https://www.sciencedirect.com/science/article/pii/S0743731599915745},\nauthor = {Ayal Itzkovitz and Assaf Schuster and Oren Zeev-Ben-Mordehai},\nkeywords = {distributed shared memory, parallel computation, data race detection, debugging tools},\nabstract = {We present a distributed algorithm, called djit, for detecting data races in dsm systems. djit is designed as a dsm add-on, detecting a race condition as soon as one is created. It instantly displays to the user the precise place in the program where the race occurred. There are no false detections, and no data races are missed. We have implemented djit on top of millipage—a fine granularity, page-based dsm system. Our implementation makes novel use of the operating system protection mechanisms. In particular, we propose a protection cache, which can be used for local logging of accesses to variables. As a result, our implementation does not increase the message complexity of the execution, piggybacking all its communication activity on top of the dsm-related messages. The performance figures show that our data race detection mechanism has only a minor influence on performance. The measured overheads, averaging only few percent, are two orders of magnitude smaller than those achieved in previous work. Thus, our technique makes the integration of on-the-fly data race detection during the regular dsm execution feasible for the first time.}\n}","doi":"10.1006/Jpdc.1999.1574"}},"savage-eraser-1997":{"title":"Eraser: a dynamic data race detector for multithreaded programs","taxon":"Reference","tags":["racepred","paper"],"route":"savage-eraser-1997.xml","metas":{"bibtex":"@Article{10.1145/265924.265927,\nauthor = {Savage, Stefan and Burrows, Michael and Nelson, Greg and Sobalvarro, Patrick and Anderson, Thomas},\ntitle = {Eraser: a dynamic data race detector for multithreaded programs},\nyear = {1997},\nissue_date = {Nov. 1997},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {15},\nnumber = {4},\nissn = {0734-2071},\nurl = {https://doi.org/10.1145/265924.265927},\ndoi = {10.1145/265924.265927},\nabstract = {Multithreaded programming is difficult and error prone. It is easy to make a mistake in synchronization that produces a data race, yet it can be extremely hard to locate this mistake during debugging. This article describes a new tool, called Eraser, for dynamically detecting data races in lock-based multithreaded programs. Eraser uses binary rewriting techniques to monitor every shared-monory reference and verify that consistent locking behavior is observed. We present several case studies, including undergraduate coursework and a multithreaded Web search engine, that demonstrate the effectiveness of this approach.},\njournal = {ACM Trans. Comput. Syst.},\nmonth = {nov},\npages = {391–411},\nnumpages = {21},\nkeywords = {binary code modification, multithreaded programming, race detection}\n}","doi":"10.1145/265924.265927"}},"mazurkiewicz-trace-1986":{"title":"Trace Theory","taxon":"Reference","tags":["trace","paper"],"route":"mazurkiewicz-trace-1986.xml","metas":{"bibtex":"@InProceedings{10.1007/3-540-17906-2_30,\nauthor=\"Mazurkiewicz, Antoni\",\neditor=\"Brauer, W.\nand Reisig, W.\nand Rozenberg, G.\",\ntitle=\"Trace theory\",\nbooktitle=\"Petri Nets: Applications and Relationships to Other Models of Concurrency\",\nyear=\"1987\",\npublisher=\"Springer Berlin Heidelberg\",\naddress=\"Berlin, Heidelberg\",\npages=\"278--324\",\nabstract=\"The concept of traces has been introduced for describing non-sequential behaviour of concurrent systems via its sequential observations. Traces represent concurrent processes in the same way as strings represent sequential ones. The theory of traces can be used as a tool for reasoning about nets and it is hoped that applying this theory one can get a calculus of the concurrent processes anologous to that available for sequential systems. The following topics will be discussed: algebraic properties of traces, trace models of some concurrency phenomena, fixed-point calculus for finding the behaviour of nets, modularity, and some applications of the presented theory.\",\nisbn=\"978-3-540-47926-0\"\n}","doi":"10.1007/3-540-17906-2_30"}},"lamport-clocks-1978":{"title":"Time, clocks, and the ordering of events in a distributed system","taxon":"Reference","tags":["racepred","trace","paper"],"route":"lamport-clocks-1978.xml","metas":{"bibtex":"@Article{10.1145/359545.359563,\nauthor = {Lamport, Leslie},\ntitle = {Time, clocks, and the ordering of events in a distributed system},\nyear = {1978},\nissue_date = {July 1978},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {21},\nnumber = {7},\nissn = {0001-0782},\nurl = {https://doi.org/10.1145/359545.359563},\ndoi = {10.1145/359545.359563},\nabstract = {The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become.},\njournal = {Commun. ACM},\nmonth = {jul},\npages = {558–565},\nnumpages = {8},\nkeywords = {multiprocess systems, distributed systems, computer networks, clock synchronization}\n}","doi":"10.1145/359545.359563"}},"latex-preamble":{"title":null,"taxon":null,"tags":[],"route":"latex-preamble.xml","metas":{}},"aarhus":{"title":"Aarhus University","taxon":"Institution","tags":[],"route":"aarhus.xml","metas":{"external":"Https://international.au.dk/"}},"andreaspavlogiannis":{"title":"Andreas Pavlogiannis","taxon":"Person","tags":["racepred","trace"],"route":"andreaspavlogiannis.xml","metas":{"external":"Https://pure.au.dk/portal/en/persons/pavlogiannis@cs.au.dk","institution":"Aarhus University","orcid":"0000-0002-8943-0722","position":"Associate Professor"}},"azadehfarzan":{"title":"Azadeh Farzan","taxon":"Person","tags":["racepred","trace"],"route":"azadehfarzan.xml","metas":{"external":"Https://www.cs.toronto.edu/~azadeh/index.html","institution":"University of Toronto","orcid":"0000-0001-9005-2653","position":"Professor"}},"camcl":{"title":"Cambridge Computer Laboratory","taxon":"Department","tags":[],"route":"camcl.xml","metas":{"venue":"[Ucam]","external":"Https://www.cst.cam.ac.uk/"}},"cmu":{"title":"Carnegie Mellon University","taxon":"Institution","tags":[],"route":"cmu.xml","metas":{"external":"Https://www.cmu.edu/"}},"daniellimws":{"title":"Daniel Lim Wee Soong","taxon":"Person","tags":[],"route":"daniellimws.xml","metas":{"external":"Https://daniellim.ws","institution":"National University of Singapore","orcid":"0009-0007-5184-6339","position":"Research Assistant"}},"dlws-0001":{"title":"Daniel Lim Wee Soong","taxon":null,"tags":[],"route":"dlws-0001.xml","metas":{"author":"False"}},"index":{"title":"Daniel Lim Wee Soong","taxon":null,"tags":[],"route":"index.xml","metas":{"author":"False"}},"dlws-0007":{"title":"Forester","taxon":null,"tags":[],"route":"dlws-0007.xml","metas":{"external":"Https://www.jonmsterling.com/jms-005P.xml"}},"gracetan":{"title":"Grace Tan","taxon":"Person","tags":[],"route":"gracetan.xml","metas":{"external":"Https://blog.grace.moe/","institution":"National University of Singapore","orcid":"0000-0002-4922-4019","position":"PhD"}},"grigorerosu":{"title":"Grigore Rosu","taxon":"Person","tags":["racepred","trace"],"route":"grigorerosu.xml","metas":{"external":"Https://fsl.cs.illinois.edu/people/grigore-rosu/","institution":"University of Illinois at Urbana-Champaign, USA","orcid":"0000-0002-3102-0421","position":"Professor"}},"hünkarcantunç":{"title":"Hünkar Can Tunç","taxon":"Person","tags":["racepred"],"route":"hünkarcantunç.xml","metas":{"institution":"Aarhus University","orcid":"0000-0001-9125-8506"}},"jonmsterling":{"title":"Jon Sterling","taxon":"Person","tags":["new-spaces","typesynth","stc","gdt","cubical"],"route":"jonmsterling.xml","metas":{"external":"Https://www.jonmsterling.com/","institution":"Cambridge Computer Laboratory","orcid":"0000-0002-0585-5564","position":"Associate Professor","phd-advisor":"Robertharper","postdoc-advisor":"Larsbirkedal"}},"larsbirkedal":{"title":"Lars Birkedal","taxon":"Person","tags":["gdt"],"route":"larsbirkedal.xml","metas":{"external":"Https://cs.au.dk/~birke/","institution":"Aarhus University","position":"Professor","orcid":"0000-0003-1320-0098"}},"maheshviswanathan":{"title":"Mahesh Viswanathan","taxon":"Person","tags":["racepred","trace","sampling-race"],"route":"maheshviswanathan.xml","metas":{"external":"Https://vmahesh.cs.illinois.edu/","institution":"University of Illinois at Urbana-Champaign, USA"}},"minjianzhang":{"title":"Minjian Zhang","taxon":"Person","tags":["racepred","sampling-race"],"route":"minjianzhang.xml","metas":{"institution":"University of Illinois at Urbana-Champaign, USA","orcid":"0000-0002-5017-2228","position":"PhD Student"}},"mosaadalthokair":{"title":"Mosaad Al Thokair","taxon":"Person","tags":["racepred","sampling-race"],"route":"mosaadalthokair.xml","metas":{"orcid":"0000-0002-6832-0604"}},"nus":{"title":"National University of Singapore","taxon":"Institution","tags":[],"route":"nus.xml","metas":{"external":"Https://nus.edu.sg/"}},"robertharper":{"title":"Robert Harper","taxon":"Person","tags":["cubical","stc"],"route":"robertharper.xml","metas":{"institution":"Carnegie Mellon University","position":"Professor","orcid":"0000-0002-9400-2941","external":"Http://www.cs.cmu.edu/~rwh"}},"umangmathur":{"title":"Umang Mathur","taxon":"Person","tags":["racepred","sampling-race","trace"],"route":"umangmathur.xml","metas":{"external":"Https://www.comp.nus.edu.sg/~umathur/","institution":"National University of Singapore","orcid":"0000-0002-7610-0660","position":"Assistant Professor"}},"uiuc":{"title":"University of Illinois at Urbana-Champaign, USA","taxon":"Institution","tags":[],"route":"uiuc.xml","metas":{"external":"Https://illinois.edu/"}},"uoft":{"title":"University of Toronto","taxon":"Institution","tags":[],"route":"uoft.xml","metas":{"external":"Https://www.utoronto.ca/"}},"zhendongang":{"title":"Zhendong Ang","taxon":"Person","tags":["racepred","trace"],"route":"zhendongang.xml","metas":{"external":"Https://ang9876.github.io/","institution":"National University of Singapore","orcid":"0009-0002-0214-3462","position":"PhD"}},"zhengshi":{"title":"Zheng Shi","taxon":"Person","tags":["racepred","trace"],"route":"zhengshi.xml","metas":{"external":"Https://www.comp.nus.edu.sg/~zs357/","institution":"National University of Singapore","orcid":"0000-0001-5021-7134","position":"PhD"}},"base-macros":{"title":"Basic macros","taxon":null,"tags":[],"route":"base-macros.xml","metas":{}},"dlws-0004":{"title":"Race prediction","taxon":"Bibliography","tags":[],"route":"dlws-0004.xml","metas":{}},"dlws-0003":{"title":"Works of Daniel Lim Wee Soong","taxon":"Bibliography","tags":[],"route":"dlws-0003.xml","metas":{}}}
